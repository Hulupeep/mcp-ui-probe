# UI-Probe LLM Configuration
# Copy this file to .env and add your API keys

# OpenAI API Key (for GPT-4 powered testing)
OPENAI_API_KEY=sk-your-openai-api-key-here

# Anthropic API Key (for Claude powered testing)
# Note: Currently limited support due to SDK compatibility
ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key-here

# LLM Provider (openai or anthropic)
# If both keys are provided, OpenAI is used by default
LLM_PROVIDER=openai

# LLM Model Selection
# For OpenAI: gpt-4-turbo-preview, gpt-4, gpt-3.5-turbo
# For Anthropic: claude-3-opus-20240229, claude-3-sonnet-20240229
LLM_MODEL=gpt-4-turbo-preview

# LLM Temperature (0-1, lower = more deterministic)
LLM_TEMPERATURE=0.3

# Enable LLM caching to reduce API calls
LLM_CACHE_ENABLED=true

# Cache TTL in milliseconds (default: 5 minutes)
LLM_CACHE_TTL=300000

# Monitoring Server Port
MONITORING_PORT=3002

# WebSocket Port
WS_PORT=3003

# Log Level (debug, info, warn, error)
LOG_LEVEL=info

# Enable Test Mode (uses mock data instead of real browser)
TEST_MODE=false

# Playwright Browser (chromium, firefox, webkit)
BROWSER_TYPE=chromium

# Browser Headless Mode
HEADLESS=true

# Default Navigation Timeout (ms)
NAVIGATION_TIMEOUT=30000

# Default Element Timeout (ms)
ELEMENT_TIMEOUT=5000

# Screenshot on Error
SCREENSHOT_ON_ERROR=true

# Maximum Retry Attempts
MAX_RETRIES=3
